{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "All the prvious steps done in EDA:"
      ],
      "metadata": {
        "id": "fOSFB37Q3t8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8q1BxZn06kl",
        "outputId": "a56a050a-26ce-4e4a-950a-49fd3771d035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "NwELLS6r1A93"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers_df = pd.read_csv(\"/content/drive/MyDrive/Zeotap_Assignment_Ansh/Customers.csv\")\n",
        "products_df = pd.read_csv(\"/content/drive/MyDrive/Zeotap_Assignment_Ansh/Products.csv\")\n",
        "transactions_df = pd.read_csv(\"/content/drive/MyDrive/Zeotap_Assignment_Ansh/Transactions.csv\")"
      ],
      "metadata": {
        "id": "r_j7os7o1HAX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers_df['SignupDate'] = pd.to_datetime(customers_df['SignupDate'])\n",
        "transactions_df['TransactionDate'] = pd.to_datetime(transactions_df['TransactionDate'])"
      ],
      "metadata": {
        "id": "0PgDXL6z1RIP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data = pd.merge(transactions_df, customers_df, on='CustomerID')\n",
        "merged_data = pd.merge(merged_data, products_df, on='ProductID')"
      ],
      "metadata": {
        "id": "zeYOA7Vp1WMi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "3wGx0SZI1nsa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Aggregating Transaction Data to Customer Level:**\n",
        "\n",
        "I group the merged_data by CustomerID and aggregate the transaction-level data to create customer-level features:\n",
        "\n",
        "TotalSpending: Sum of all transaction values for each customer.\n",
        "\n",
        "TotalTransactions: Count of transactions each customer has made.\n",
        "\n",
        "AvgSpendingPerTransaction: Average spending per transaction.\n",
        "\n",
        "PreferredCategory: The most frequent product category purchased by each customer (based on transaction data).\n"
      ],
      "metadata": {
        "id": "5jhFvqVl4Dqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Encoding Categorical Features:**\n",
        "\n",
        "I use LabelEncoder to convert the PreferredCategory and Region (which are categorical) into numeric values, making it usable in machine learning models."
      ],
      "metadata": {
        "id": "oxg_cP6Z4SwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Merging Demographic Information:**\n",
        "\n",
        "I merge customer_features (aggregated transactional features) with customers_df (demographic information like Region) on CustomerID to create a comprehensive customer profile."
      ],
      "metadata": {
        "id": "_T2DShu64S_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Normalizing Numerical Features:**\n",
        "\n",
        "I normalize numerical features (TotalSpending, TotalTransactions, and AvgSpendingPerTransaction) using StandardScaler to ensure they are on a similar scale for distance/similarity calculations."
      ],
      "metadata": {
        "id": "z9w2KwMb4jK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Building the Similarity Matrix:**\n",
        "\n",
        "I created a cosine similarity matrix using the features Region, TotalSpending, TotalTransactions, AvgSpendingPerTransaction, and PreferredCategory to calculate how similar each customer is to all others based on these attributes."
      ],
      "metadata": {
        "id": "7Dx9SLNM4tsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Recommendation Logic:**\n",
        "\n",
        "For each of the first 20 customers (C0001 to C0020):\n",
        "\n",
        "I calculate their similarity scores with every other customer.\n",
        "\n",
        "I exclude the self-comparison (i.e., the target customer comparing themselves).\n",
        "\n",
        "I select the top 3 most similar customers based on the highest similarity scores."
      ],
      "metadata": {
        "id": "XvBuBFpM4t0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Saving Results:**\n",
        "\n",
        "We create a Lookalike.csv file where for each target customer, we save the top 3 similar customers and their respective similarity scores."
      ],
      "metadata": {
        "id": "zeGzPujL5V47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Aggregate transaction data to customer level\n",
        "customer_features = merged_data.groupby('CustomerID').agg(\n",
        "    TotalSpending=('TotalValue', 'sum'),\n",
        "    TotalTransactions=('TransactionID', 'count'),\n",
        "    AvgSpendingPerTransaction=('TotalValue', 'mean'),\n",
        "    PreferredCategory=('Category', lambda x: x.value_counts().idxmax())\n",
        ").reset_index()\n",
        "\n",
        "# Encode categorical features\n",
        "le = LabelEncoder()\n",
        "customer_features['PreferredCategory'] = le.fit_transform(customer_features['PreferredCategory'])\n",
        "\n",
        "# Add demographic information from Customers.csv\n",
        "customer_profiles = pd.merge(customers_df, customer_features, on='CustomerID')\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = ['TotalSpending', 'TotalTransactions', 'AvgSpendingPerTransaction']\n",
        "customer_profiles[numerical_cols] = scaler.fit_transform(customer_profiles[numerical_cols])\n",
        "le_region = LabelEncoder()\n",
        "customer_profiles['Region'] = le_region.fit_transform(customer_profiles['Region'])\n",
        "# Build a similarity matrix\n",
        "feature_cols = ['Region', 'TotalSpending', 'TotalTransactions', 'AvgSpendingPerTransaction', 'PreferredCategory']\n",
        "similarity_matrix = cosine_similarity(customer_profiles[feature_cols])\n",
        "\n",
        "# Recommendation Logic\n",
        "lookalike_results = {}\n",
        "\n",
        "for i, target_customer in enumerate(customer_profiles['CustomerID']):\n",
        "    # Skip if not in the first 20 customers\n",
        "    if target_customer not in [f\"C{i:04}\" for i in range(1, 21)]:\n",
        "        continue\n",
        "\n",
        "    # Get similarity scores for the target customer\n",
        "    similarity_scores = list(enumerate(similarity_matrix[i]))\n",
        "\n",
        "    # Sort by similarity score (descending) and exclude self-comparison\n",
        "    similar_customers = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "    similar_customers = [(customer_profiles.iloc[j]['CustomerID'], score)\n",
        "                         for j, score in similar_customers if j != i][:3]\n",
        "\n",
        "    # Save to lookalike results\n",
        "    lookalike_results[target_customer] = similar_customers\n",
        "\n",
        "# Create Lookalike.csv\n",
        "lookalike_df = pd.DataFrame({\n",
        "    'CustomerID': list(lookalike_results.keys()),\n",
        "    'Lookalikes': [str(lst) for lst in lookalike_results.values()]\n",
        "})\n",
        "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
        "\n",
        "print(\"Lookalike recommendations saved to Lookalike.csv!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QY9C5Kz1fTO",
        "outputId": "3c405716-00b0-4c23-fb54-5a4ea388cffe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lookalike recommendations saved to Lookalike.csv!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is The code to calculate Precision and Recall if the ground truth data is given:"
      ],
      "metadata": {
        "id": "QB-zqVPv5z4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assume ground_truth_dict is a dictionary where:\n",
        "# # key = customer_id, value = set of true similar customers\n",
        "# # e.g., ground_truth_dict = {'C0001': {'C0002', 'C0003'}, 'C0002': {'C0001', 'C0004'}, ...}\n",
        "\n",
        "# def calculate_precision_recall(lookalike_results, ground_truth_dict, top_n=3):\n",
        "#     precision_list = []\n",
        "#     recall_list = []\n",
        "\n",
        "#     for customer_id, recommended_customers in lookalike_results.items():\n",
        "#         true_similars = ground_truth_dict.get(customer_id, set())\n",
        "\n",
        "#         # Get top_n recommended customers\n",
        "#         recommended_set = {rec[0] for rec in recommended_customers[:top_n]}\n",
        "\n",
        "#         # Calculate precision\n",
        "#         intersection = true_similars.intersection(recommended_set)\n",
        "#         precision = len(intersection) / top_n if top_n > 0 else 0\n",
        "#         precision_list.append(precision)\n",
        "\n",
        "#         # Calculate recall\n",
        "#         recall = len(intersection) / len(true_similars) if len(true_similars) > 0 else 0\n",
        "#         recall_list.append(recall)\n",
        "\n",
        "#     # Average precision and recall\n",
        "#     avg_precision = sum(precision_list) / len(precision_list) if precision_list else 0\n",
        "#     avg_recall = sum(recall_list) / len(recall_list) if recall_list else 0\n",
        "\n",
        "#     return avg_precision, avg_recall\n",
        "\n",
        "# # Example usage:\n",
        "# avg_precision, avg_recall = calculate_precision_recall(lookalike_results, ground_truth_dict)\n",
        "# print(f\"Average Precision: {avg_precision}\")\n",
        "# print(f\"Average Recall: {avg_recall}\")\n"
      ],
      "metadata": {
        "id": "Vuh7S_rs3KeI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZTv4aNGM5xKd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}